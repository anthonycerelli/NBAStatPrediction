{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.4990430121584515"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_RPG.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data analysis - using 2016 data for machine learning model, trying to predict PPG, RPG, and APG for 2017 season\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv(r\"/Users/anthonycerelli/Desktop/programming/MachineLearning_NBA/nba-players-stats/Seasons_Stats_Final_allYears.csv\")\n",
    "#data analysis -> average PPG: 9.62, average RPG: 4.01, average APG: 2.08\n",
    "\n",
    "del df['Player']\n",
    "\n",
    "#use one-hot encoding for Pos column. Everything else is nominal data and can be fed directly into model\n",
    "\n",
    "df = df[df['Pos'] != \"PG-SG\"]\n",
    "df = df[df['Pos'] != \"SF-SG\"]\n",
    "df = df[df['Pos'] != \"C-PF\"]\n",
    "df = df[df['Pos'] != \"SG-PG\"]\n",
    "df = df[df['Pos'] != \"SG-SF\"]\n",
    "df = df[df['Pos'] != \"PF-C\"]\n",
    "df = df[df['Pos'] != \"SF-PF\"]\n",
    "df = df[df['Pos'] != \"PF-SF\"]\n",
    "df = df[df['Pos'] != \"SG-PF\"]\n",
    "df = df[df['Pos'] != \"PG-SF\"]\n",
    "df = df[df['Pos'] != \"C-SF\"]\n",
    "\n",
    "df = df[df['G'] >= 60]\n",
    "\n",
    "cols = df.columns.values\n",
    "\n",
    "for value in cols:\n",
    "    \n",
    "    df = df[df[value] != \"\"]\n",
    "    df = df[df[value] != \" \"]\n",
    "    df = df[df[value].notna()]\n",
    "\n",
    "y_PPG = df['PPG']\n",
    "y_RPG = df['RPG']\n",
    "y_APG = df['APG']\n",
    "\n",
    "del df['PPG']\n",
    "del df['RPG']\n",
    "del df['APG']\n",
    "\n",
    "df = pd.get_dummies(df, columns = ['Pos']) #converts dataframe column Pos into one hot encoded columns\n",
    "\n",
    "\n",
    "X = df\n",
    "#X is the standalone input variables, where I am first going to test these values all against each variable\n",
    "\n",
    "#PPG model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train_PPG, y_test_PPG = train_test_split(X, y_PPG, test_size = 0.2, random_state=1)\n",
    "\n",
    "X_train, X_test, y_train_APG, y_test_APG = train_test_split(X, y_APG, test_size = 0.2, random_state=1)\n",
    "\n",
    "X_train, X_test, y_train_RPG, y_test_RPG = train_test_split(X, y_RPG, test_size = 0.2, random_state=1)\n",
    "\n",
    "y_test_PPG = y_test_PPG.to_numpy()\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1417629210776792\n",
      "0.9652674548400193\n",
      "3.0152285652868134\n",
      "0.7676114447543624\n",
      "2.333072509803923\n"
     ]
    }
   ],
   "source": [
    "#PPG model\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#RF model\n",
    "model_rf = RandomForestRegressor(n_estimators=500, oob_score=True, random_state=100)\n",
    "model_rf.fit(X_train, y_train_PPG) \n",
    "pred_train_rf= model_rf.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train_PPG,pred_train_rf)))\n",
    "print(r2_score(y_train_PPG, pred_train_rf))\n",
    "\n",
    "pred_test_rf = model_rf.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test_PPG,pred_test_rf)))\n",
    "print(r2_score(y_test_PPG, pred_test_rf))\n",
    "print(mean_absolute_error(y_test_PPG, pred_test_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PPG model\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "#Bayesian ridge model\n",
    "model_PPG = BayesianRidge(normalize=True)\n",
    "model_PPG.fit(X_train, y_train_PPG)\n",
    "y_pred_class = model_PPG.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "mae = mean_absolute_error(y_test_PPG, y_pred_class)\n",
    "\n",
    "print(\"mean absolute error: \" + str(mae))\n",
    "print(np.sqrt(mean_squared_error(y_test_PPG, y_pred_class)))\n",
    "print(r2_score(y_test_PPG, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error: 0.5897012763948102\n",
      "0.8248952702887855\n",
      "0.8553675177643267\n"
     ]
    }
   ],
   "source": [
    "#APG model\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#support vector regression model \n",
    "model_APG = SVR(C=100)\n",
    "model_APG.fit(X_train, y_train_APG)\n",
    "y_pred_class = model_APG.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "mae = mean_absolute_error(y_test_APG, y_pred_class)\n",
    "\n",
    "print(\"mean absolute error: \" + str(mae))\n",
    "print(r2_score(y_test_APG, y_pred_class))\n",
    "print(np.sqrt(mean_squared_error(y_test_APG,y_pred_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error: 0.5934205090308599\n",
      "0.84565750351808\n",
      "0.8288482350035694\n"
     ]
    }
   ],
   "source": [
    "#APG model\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "#Bayesian Ridge Model\n",
    "model_APG = BayesianRidge(normalize=True)\n",
    "model_APG.fit(X_train, y_train_APG)\n",
    "y_pred_class = model_APG.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "mae = mean_absolute_error(y_test_APG, y_pred_class)\n",
    "\n",
    "print(\"mean absolute error: \" + str(mae))\n",
    "print(np.sqrt(mean_squared_error(y_test_APG, y_pred_class)))\n",
    "print(r2_score(y_test_APG, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error: 0.8974195550776035\n",
      "1.2700278091605928\n",
      "0.8042483727937485\n"
     ]
    }
   ],
   "source": [
    "#RPG model\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#ridge model\n",
    "model_RPG = Ridge()\n",
    "model_RPG.fit(X_train, y_train_RPG)\n",
    "y_pred_class = model_RPG.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "mae = mean_absolute_error(y_test_RPG, y_pred_class)\n",
    "\n",
    "print(\"mean absolute error: \" + str(mae))\n",
    "print(np.sqrt(mean_squared_error(y_test_RPG, y_pred_class)))\n",
    "print(r2_score(y_test_RPG, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute error: 0.8970603039500552\n",
      "1.2703976182405206\n",
      "0.8041343575445336\n"
     ]
    }
   ],
   "source": [
    "#RPG model\n",
    "\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "#bayesian ridge model\n",
    "model_RPG = BayesianRidge(normalize=True)\n",
    "model_RPG.fit(X_train, y_train_RPG)\n",
    "y_pred_class = model_RPG.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "mae = mean_absolute_error(y_test_RPG, y_pred_class)\n",
    "\n",
    "print(\"mean absolute error: \" + str(mae))\n",
    "print(np.sqrt(mean_squared_error(y_test_RPG, y_pred_class)))\n",
    "print(r2_score(y_test_RPG, y_pred_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
